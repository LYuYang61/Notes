# 1、多无人机分布式一致性相关论文
### 1、多无人机共识方法
- 论文地址：https://doi.org/10.1109/TITS.2023.3300871
#### 1.1 研究问题
- **无人机 ( UAV ) 集群系统的分布式态势感知 ( SA ) 共识问题**
- 在复杂的任务环境中，传统的中心化架构无法满足大规模无人机蜂群系统对高自主性的需求，并且在面对局部不确定性时鲁棒性较差
- 因此，本文提出一种分布式方法，让多架无人机在各自进行局部感知的同时，能够通过相互协作形成一个共享的、一致的全局态势认知
#### 1.2 创新贡献
1. 提出一种**新的分布式情境感知共识模型**：首次将相对共识和绝对共识结合起来
	- **相对共识**：确保每架无人机的个体认知与其邻居的认知达成一致
	- **绝对共识**：旨在使整个系统的共识认知与真实的态势情况对齐
	- 这种双重共识的建模方式，不仅解决了无人机之间的认知协同问题，还确保了最终共识的准确性和高质量
	- **双重共识的必要性**：
		- 以往的研究多采用中心化架构，或只关注无人机间的相对共识。然而，这种共识并不保证与“真实情况”的对齐
		- 本将**个体间认知的一致性（相对共识）和群体认知与现实的准确性（绝对共识）** 结合在一个数学模型中，这是一种全新的、更具实践意义的视角
	- **认知不确定性的处理**：
		- 无人机的个体认知会受到**飞行高度差异、观察角度限制、建筑物遮挡和极端天气**等不确定因素的影响
		- 本文引入**模糊偏好关系**来描述无人机对目标的认知偏好，这种模糊建模方法能够更好地处理不精确、不完整的态势信息
2. 构建**双循环决策框架**：
	- **内循环**：负责无人机之间的实时协同，包括对**个体认知**和**系统协作**两个阶段
	- **外循环**：引入 **PID 控制器**，通过对共识权重的反馈校正，提高了系统对真实态势的绝对共识，有效应对各种干扰，保证了共识的稳健性
	![image.png](https://qingwu-oss.oss-cn-heyuan.aliyuncs.com/lian/img/20250918150732.png)
3. 设计具有**双模态切换的分布式协调算法**：能够根据无人机自身的**局部共识参数** $c^k_L$ 动态切换两种交互模式
	- **平等模式**：当局部共识度高时（$c^k_L>= c^s_L$），无人机之间进行对等的信息交换
	- **分层模式**：当局部共识度低时（$c^k_L<c^s_L$），无人机会请求与“智力水平“（通过共识权重反映）更高的邻居进行交互
	- 当某 UAV 节点 k 的局部共识度 $c^k_L>=c^{min}_L$ 时，保持当前认知 $P^k$  不变；否则根据规则修正认知，并在两种交互模式中选择
	- 阈值条件 $c^{min}_L$ 用于判定局部是否满足一致
	- 阈值条件 $c^s_L$ 用于判定局部一致性的不同交互模式（平等/分层）
	- 这种设计避免了传统方法中“实时连续通信”的昂贵代价，从而大大提高了通信效率，解决了现有分布式梯度下降（DGD）方法收敛慢且通信代价大的问题
#### 1.3 研究方法与相较既有方法的优势
- **方法学路径**：模型层->优化层->框架层->算法层->收敛分析->仿真验证的闭环范式
    1. 模型层：引入“模糊偏好关系理论”和“时变无向图”刻画异构传感和随时间变化的通信拓扑，使 SA 共识建立在更贴近现实的表征之上
    2. 优化层：将共识问题表述为分布式优化，使两级共识目标可量化、可权衡、可分析
    3. 框架层：双环设计，内环两阶段（个体认知、系统协作）与外环反馈耦合，提升扰动下稳定性
    4. 算法层：双模机制+历史信息反馈，强调低通信负担与收敛性
- 文中定义了三个**评估指标**：
	- **全局共识参数** $c_G$：反映相对一致性水平
	- **群体目标函数** F：反映群体的绝对一致性水平
	- **真实群体目标优化函数** $F^*$：反映群体的绝对一致性优化水平
- **与传统方法（如集中式方法与 DGD）相比的优势**：
    - **去中心化与鲁棒性**：避免集中式的单点故障和带宽瓶颈，外环反馈增强抗扰动能力
    - **通信效率**：依赖历史反馈、减少频繁全量通信，仅在必要时（即局部共识度低时）才进行更密集的交互，优于需要高频梯度交换的 DGD 式方法
#### 1.4 拓展研究设想 AI
1. **基于深度强化学习（DRL）的自适应共识权重学习**：
	- 问题：目前论文中的共识权重（wk​）是通过一个固定的 PID 控制器来调整的，其参数需要经验性地手动调优。这在动态、未知的环境中可能表现不佳。
	- 设想：将共识权重调整问题建模为一个马尔可夫决策过程。每个无人机智能体作为强化学习代理，其状态包括局部共识参数、邻居的共识权重等；其动作是调整自身共识权重的策略；其奖励是系统共识质量和通信效率的综合函数。通过深度强化学习，无人机可以在线自主学习最优的共识权重调整策略，从而在复杂环境中实现更高效、更鲁棒的分布式共识。
2. **考虑信任度和声誉机制的弹性共识算法**：
	- 问题：在分层模式下，无人机倾向于向“智力水平”更高（即共识权重更高）的邻居请求交互。但这种“智力水平”并不能完全等同于信任度，特别是当存在恶意或故障无人机时。
	- 设想：在双循环框架中引入一个基于区块链或去中心化账本的信任和声誉机制。每个无人机不仅维护自己的共识权重，还维护一个关于邻居的信任得分。这个信任得分基于邻居过去提供信息的准确性和对共识的贡献度进行动态更新。在进行信息交换和权重校正时，无人机优先与信任得分高的邻居进行协作。这样，即使某个无人机由于故障或攻击提供了错误信息，其信任得分会降低，其他无人机将自动减少对其信息的依赖，从而从根本上增强整个系统的弹性（Resilience）和安全性。这能有效应对论文中未深入讨论的对抗性威胁 。
3. **认知-控制一体化的“目标导向SA共识与轨迹协同”**：
	- 设想：将 SA 共识目标与控制/轨迹优化联立，即在分布式优化目标里加入“任务效能”（如目标跟踪误差、覆盖度、风险约束），把绝对共识与任务绩效共同最优化。利用分布式 MPC 或分层优化（上层 SA 共识、下层轨迹与资源分配），外环反馈同时调节“共识增益—控制增益”的耦合。
4. **语义层一致性的跨模态/跨域对齐与可解释性**：
	- 设想：在模糊偏好关系之上引入“语义一致性层”，利用图神经网络或因果图对异构传感（视觉、雷达、通信侦察）生成的高层语义进行对齐；在 ck_L 与 cG 的定义中引入“语义一致度”子项。外环反馈除数值误差外，也反馈“语义冲突”信号，并触发“语义仲裁器”（基于可信来源、历史成功率、场景上下文先验）。

### 2、多无人机三维轨迹规划与资源分配的分布式动态一致性（DDC）协议
- 论文地址：https://doi.org/10.1016/j.vehcom.2025.100969
#### 2.1 研究问题
- 在多无人机系统中，如何在分布式协同框架下联合优化三维轨迹规划与无人机资源分配，以降低任务总成本（由归一化时延与归一化能耗之和构成），同时克服集中式通信在通信范围、能效与时延方面的局限
- 本文**基于分布式一致性理论提出一种结合 DDPG 的分布式动态一致性（DDC）方法**，并比较三种一致性机制（DVC、DEC、DDVC）的性能，还考察不同网络连通度（部分、适中、完全）的影响与与集中/自治决策基线的对比
#### 2.2 创新贡献
- 提出分布式动态一致性（DDC）算法，将深度学习中的 DDPG 与一致性控制理论融合，使各 UAV 基于邻居信息独立决策，同时在全网实现共享信息的一致性收敛，从而优化全局代价
- 设计并比较三种一致性策略：
	- **分布式速度一致性 DVC**：理想化场景，假设无人机之间能完美共享速度信息以达成一致
	- **分布式误差一致性 DEC**：在这种情况下，除了其他变量，无人机之间共享的是其速度动态误差，并将其作为附加信息输入到批评网络（critic network）中，这是论文中被认为最有效的技术
	- **分布式动态速度一致性 DDVC**：考虑了无人机动力学信息共享，旨在研究其对行动值和奖励的影响
- 在不同网络连通度（全连、部分连、中等连）下，将所提分布式方案与集中式训练-集中式执行（CTCE）以及完全自主（无一致性）决策进行对比验证
![image.png](https://qingwu-oss.oss-cn-heyuan.aliyuncs.com/lian/img/20250919192334.png)
- 明确问题目标为最小化全局计算成本 z（归一化总时延+能耗之和），在满足通信、计算与环境约束（例如服务唯一性、飞行边界、电池上限、任务时限等）下进行优化
#### 2.3 研究方法与相较既有方法的优势
- **克服传统集中式方法的瓶颈**：与需要单一中央控制器收集所有信息并做出全局决策的集中式方法相比，该分布式方法避免了单点故障，提高了系统的可扩展性和鲁棒性
- **弥补现有分布式方法的缺陷**：大多数现有方法采用的是集中式信息交换和去中心化计算，但该论文实现了**完全去中心化**的信息交换，每个无人机只与邻居节点通信。这更符合实际分布式系统的物理约束，减少了通信开销和延迟 
- **解决信息不完美问题**：通过将误差作为一致性变量，DEC 方法解决了动态环境中由于信息不及时或不精确而导致的决策错误问题

### 3、多无人机分布式轨迹设计
- 论文地址：https://doi.org/10.1109/TCOMM.2020.3013599
#### 3.1 研究问题
- 在“蜂窝化的无人机互联网”场景中，多 UAV 需要持续地对分散在不同地理位置的多个任务目标进行感知，并把感知结果通过蜂窝上行回传至基站（BS）
- 本文设计一种分布式轨迹规划算法，以**最小化多无人机蜂窝物联网中所有无人机协作感知和数据传输任务的信息年龄**（Age of Information, AoI）【数据的“新鲜度”】
- 本文核心目标：在“分布式”条件下，为多 UAV 设计协同轨迹（含任务分配与感知位点选择），最小化给定时段内的“累计 AoI”
#### 3.2 创新贡献
##### 1、分布式“感知-发送”(sense-and-send) 协议
- 将任务执行流程划分为决策、空闲、感知和传输四种周期，使得无人机能够根据系统状态独立作出决策，同时又能通过与基站的信息交换实现分布式协作
![image.png](https://qingwu-oss.oss-cn-heyuan.aliyuncs.com/lian/img/20250920173203.png)
- 在信息交换中（每个周期开始），每架无人机向 BS 报告其状态，包括当前位置、所选任务、该任务的感知位置以及上一次感知结果中仍在等待传输的数据量。然后，BS 广播系统的状态，包括所有无人机的状态和每个任务的 AoI
- **决策周期**：
	- 无人机完成其选定任务所需的感知和传输，就会到达决策周期
	- 在决策周期内，无人机确定其新选择的任务和相应的感知位置
	- 在这个周期中，假设无人机保持在其当前位置，直到它完成了决策过程
- **空闲周期**：
	- 处于空循环中的无人机以速度 vmax 直接移动到各自的感知位置
	- 当无人机到感知位置的距离在最大飞行距离之内，在当前周期内可以到达新的感知位置
	- 否则，无人机以速度 vmax 向感知位置移动，但不会在该周期内到达
- **感知周期**：
	- 无人机各自感知目标
	- 假设感知过程可以在一个周期内完成，无人机在感知周期内悬停在它们的感知位置上
	- 感知成功与否是一个概率事件，其成功率与无人机和任务之间的距离有关
	- 无人机尝试收集任务数据，并将感知结果传输给 BS
- **传输周期**：
	- 无人机传输其采集的感知结果
	- 假设无人机在传输周期内保持位置不变，直到它们的感知结果被成功传输到 BS
	- 避免 BS 判定感知结果无效时，无人机不得不再次飞回感知目标
	- 传输周期数由感知结果产生的数据量和传输速率共同决定
- **注意**：
	- 在无人机完成报告其感知结果的传输周期后，BS 将在下一个周期开始时通知无人机所选任务的 Aol
	- 如果所选任务的 Aol 没有降低至一个周期，无人机知道其先前传输的感知结果无效
	- 然后，无人机立刻开启另一个感知周期并随后传输新的感知结果
	- 感知周期和传输周期的顺序将重复进行，直到在 BS 收到有效的感知结果
	- 如果多架无人机执行相同的任务，则当 BS 处的任务收到任何有效的感知结果时，它们将认为该任务已经完成
##### 2、将问题建模为马尔可夫决策过程（MDP）
- **环境**：蜂窝化 UAV 互联网
- **智能体**：每架无人机都被视为一个独立的智能体，在每个周期开始时，每个智能体都会基于当前状态独立地作出决策
- **状态空间**：包含了智能体在作出决策时需要的所有信息
	- **无人机自身的信息**：无人机在 t 时刻的位置
	- **任务信息**：所有任务在 t 时刻的 Aol【自该任务上次成功更新数据以来经过的时间】
	- **其他无人机的信息**：其他所有无人机在 t 时刻的位置
	- **待传输数据的信息**：若有任务数据尚未传输，其数据量也是状态的一部分
- **动作空间**：智能体可以执行的所有可能行为的集合，本文建模为**混合动作空间**
	- **离散动作**：无人机选择执行哪个任务，或者选择空闲，这部分动作是离散的
	- **连续动作**：如果选择了执行某个任务，还需要选择一个感知位置，由于感知位置可以在二维平面内任意选择，这部分动作是连续的
- **状态转移函数**：
	- 描述了在给定当前状态和智能体所执行的动作后，系统如何转移到下一个状态，这个过程是不确定的
	- 包括：周期数，无人机位置变化，收集的数据量，传输的数据量等
- **奖励函数**：定义了智能体在执行某个动作后所获得的即时奖励
	- 本文目标是**最小化累计的 Aol**
	- 当无人机成功完成一个任务（即感知并传输数据成功）后，该任务的 Aol 会重置为 0，同时所有任务的 Aol 会减少，从而获得一个正向的奖励
	- 如果一个周期内没有无人机完成任务，所有任务的 Aol 会增加，系统会得到一个负奖励
	![image.png](https://qingwu-oss.oss-cn-heyuan.aliyuncs.com/lian/img/20250921164415.png)
##### 3、多智能体深度强化学习算法（CA2C）
- 本文指出现有工作多数只做“感知”不联合“传输”，或是非协作/集中式协作；而且未把“持续感知”与 AoI 最小化放在一起
- 本文以多智能体深度强化学习为框架，提出 CA2C，融合 DQN 与 DDPG 思想，针对“离散任务选择+连续感知点选择”的复合动作进行策略学习
- **算法架构**：演员-评论家 (Actor-Critic) 框架
	- **演员网络**：负责学习策略，即在给定状态下采取什么动作，目标是最大化长期累积奖励
	- **评论家网络**：负责评估策略，即评估演员网络采取的动作的价值（或 Q 值），会根据环境反馈的即时奖励来更新自己，然后用其评估来指导演员网络的学习
- **CA2C 的创新性设计**：
	- **离散动作的 Q 值评估**：
		- 为了处理离散的任务选择，本文将**评论家网络**设计为输出一个 Q 值向量，这个向量的每个元素对应于一个离散任务的 Q 值
		- 评论家可以评估选择不同任务所带来的潜在回报，从而为演员网络的决策提供依据
	- **连续动作的策略生成**：
		- 对于连续的感知位置选择，**演员网络**被设计成一个**策略网络**，它会直接输出一个连续的位置坐标
		- 这个策略网络会根据评论家网络的反馈，调整其参数，以便生成更优的感知位置
	- 演员和评论家网络在训练时是**协同工作**的：
		- 评论家网络在评估动作时，会同时考虑离散任务和连续位置，并生成一个综合性的评估信号
		- 这个信号被用于更新演员网络，使得演员网络能够学习到一个同时考虑任务选择和位置选择的最优策略
		![image.png](https://qingwu-oss.oss-cn-heyuan.aliyuncs.com/lian/img/20250921170407.png)
- **算法训练与优化过程**：
	1. **初始化**：随机初始化演员网络和评论家网络的参数
	2. **数据收集**：无人机作为智能体，根据当前状态和演员网络的策略，选择一个任务和感知位置，并执行动作
	3. **环境交互**：执行动作后，无人机与环境进行交互（例如，感知任务，传输数据），环境会返回一个新的状态和即时奖励
	4. **经验回放**：将（当前状态，动作，奖励，新状态）这个元组存储到**经验回放缓冲区**中。这个缓冲区有助于打破数据之间的相关性，提高训练的稳定性
	5. **网络更新**：从经验回放缓冲区中随机采样一批数据，利用它们来更新演员网络和评论家网络的参数
#### 3.3 研究方法与相较既有方法的优势
- **方法框架**：
    - 系统协议设计（分布式信息交换与周期化执行）-> MDP抽象（状态/复合动作/状态转移/奖励）-> 多智能体深度强化学习（CA2C）
- **特点和优势**：
    - **无需先验知识**：传统的优化方法通常需要一个精确的环境模型，而本论文所面对的感知和传输模型是未知的。深度强化学习的优势在于它能够通过与环境的交互，从经验中学习最优策略，而无需事先了解状态转移函数
    - **应对高维空间**：无人机的状态（位置、AoI、待传输数据量等）和动作（任务、感知位置）空间是巨大的，且包含连续变量。DRL 通过深度神经网络的泛化能力，能够有效地处理这种高维且包含连续变量的状态和动作空间，解决了传统 Q-learning 方法因查找表过大而导致的收敛问题
    - **实时决策能力**：所提出的分布式协议和 CA2C 算法允许无人机在每个周期开始时基于当前状态独立地做出决策，这使其具备了实时、动态的轨迹规划能力，能够适应不断变化的环境和任务 AoI
#### 3.4 拓展研究设想 AI
1. **面向边缘计算的 AoI-Energy 联合优化**
	- 问题：本文的核心是最小化 AoI，但没有深入考虑无人机的能耗。一个更有挑战性的问题是在最小化 AoI 的同时，最大化无人机的续航时间
	- 设想：需要将能量消耗（例如，飞行、悬停和数据传输的能耗）作为回报函数的一部分，或作为新的约束条件。此外，可以考虑在无人机上部署边缘计算能力，让无人机可以自主判断感知结果的有效性，从而减少无效数据传输带来的能耗和通信开销。
2. **基于信任与声誉机制的非完全协作系统**
	- 问题：本文假设所有无人机都是完全协作的，并且不会有故障。一个更贴近现实的设想是考虑一个部分协作甚至包含恶意或故障无人机的系统
	- 设想：可以引入信任或声誉机制，让无人机在决策时不仅考虑 AoI，还要考虑其他无人机的“声誉”和可靠性。这需要设计新的奖励函数和学习范式，以鼓励诚实协作并惩罚“搭便车”或恶意行为，从而提高整个系统的鲁棒性。
3. **基于图神经网络（GNN）的动态拓扑自适应轨迹优化**
	- 问题：本文中的协作主要依赖于基站作为信息广播中心。然而，在一些复杂场景（如无基站覆盖的灾区）中，无人机可能需要直接进行对等（P2P）通信。此外，无人机之间的通信拓扑是动态变化的，这会影响信息共享和协作效率。
	- 设想：将无人机系统建模为一个动态图，其中节点是无人机和任务，边是它们之间的通信或感知关系。然后，使用图神经网络（GNN）来处理这种动态拓扑结构。每个无人机智能体的策略网络不再只输入本地和基站信息，而是输入一个表示整个系统拓扑结构的图。GNN的聚合机制能够让每个无人机高效地汇集其邻居信息，从而在没有基站的情况下也能做出最优的分布式决策。这能让研究从“中心化信息”的假设拓展到“无中心”的完全分布式自适应协作
4. **动态任务生成与优先级调度**
	- 问题：一个更具动态性的问题是任务会随时间或事件动态生成，并且具有不同的紧急程度（优先级）。例如，在自然灾害监测中，新塌方区域可能突然出现。
	- 设想：通过元学习（Meta-Learning）或终身学习（Lifelong Learning），让多智能体系统能够快速适应新出现的任务，并根据任务的实时优先级动态调整其轨迹和协作策略，而无需从头开始重新训练。
